{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "# nlp = spacy.load(\"en_core_sci_scibert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill your train path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_paths = {\n",
    "    'train': '../data/trainingdata_v3/train/',\n",
    "    'dev': '../data/trainingdata_v3/dev/'\n",
    "}\n",
    "dataset_types = ['train', 'dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_type in dataset_types:\n",
    "    filenames = next(walk(my_paths[dataset_type]), (None, None, []))[2]\n",
    "    # print(filenames[:20])\n",
    "    filenames_ann = [filename for filename in filenames if 'ann' in filename]\n",
    "    filenames_txt = [filename for filename in filenames if 'txt' in filename]\n",
    "    filenames_ann.sort()\n",
    "    filenames_txt.sort()\n",
    "    filenames_ann_txt = list(zip(filenames_ann, filenames_txt))\n",
    "\n",
    "    df_dataset = pd.DataFrame()\n",
    "    for index, (filename_ann, filename_txt) in enumerate(filenames_ann_txt):\n",
    "        # print('Current index:', index)\n",
    "        df_ann = pd.read_csv(my_paths[dataset_type] + filename_ann, sep='\\t', names=['entity-event-context', 'classification-type', 'value'])\n",
    "        df_entities = pd.DataFrame()\n",
    "        # print(filename_ann)\n",
    "        if (df_ann.apply(lambda row: row['value'] if row['entity-event-context'][0]== 'T' else '', axis=1).shape[0] > 0):\n",
    "            df_entities['entities'] = df_ann.apply(lambda row: row['value'].lower() if row['entity-event-context'][0]== 'T' else '', axis=1)\n",
    "            df_entities = df_entities[df_entities['entities'] != '']\n",
    "            df_entities = df_entities.drop_duplicates(['entities'])\n",
    "            entitites =  ','.join(df_entities.entities)\n",
    "        else:\n",
    "            entitites = ''\n",
    "        with open(my_paths[dataset_type] + filename_txt, 'r') as file:\n",
    "            text = file.readlines()\n",
    "        text = ''.join(text).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        text_filtered = ''\n",
    "        for char_index, char in enumerate(text):\n",
    "            if char_index < (len(text)-1):\n",
    "                if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "                    text_filtered += char\n",
    "        text_filtered = text_filtered.lower()\n",
    "        row = pd.DataFrame({ 'filename': filename_ann[:-4], 'text': [text_filtered], 'entities': [entitites]})\n",
    "        df_dataset = pd.concat([df_dataset, row], ignore_index=True)\n",
    "\n",
    "    # print(df_dataset.head())\n",
    "    df_dataset.to_csv(my_paths[dataset_type] + dataset_type + '_entities.tsv', sep='\\t')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for dataset_type in [dataset_types[0]]:\n",
    "    df = pd.concat([df, pd.read_csv(my_paths[dataset_type] + dataset_type + '_entities.tsv', sep='\\t')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['filename', 'text', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, ['text']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(df.loc[0, ['text']].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "df['tokenizer_length_text'] = df.apply(lambda row: len(tokenizer.encode(row['text'])) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>tokenizer_length_text</th>\n",
       "      <th>tokenizer_length_entites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101-01</td>\n",
       "      <td>record date: 2079-05-12 mercy care center mer...</td>\n",
       "      <td>lipitor,synthroid</td>\n",
       "      <td>593</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101-02</td>\n",
       "      <td>record date: 2079-06-23 mercy care center mer...</td>\n",
       "      <td>atenolol,hydrochlorothiazide</td>\n",
       "      <td>442</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101-03</td>\n",
       "      <td>record date: 2079-08-11 mercy care center mer...</td>\n",
       "      <td>atenolol,ramipril,lipitor,long acting nitrate,...</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105-02</td>\n",
       "      <td>record date: 2147-03-11 reason for consult: 6...</td>\n",
       "      <td>lovastatin,fludrocortisone,celexa,proamatine,u...</td>\n",
       "      <td>1021</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106-01</td>\n",
       "      <td>record date: 2083-11-17 northwest iowa health...</td>\n",
       "      <td>vioxx,advil,ativan,zestril,diabetes medication...</td>\n",
       "      <td>754</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>394-04</td>\n",
       "      <td>record date: 2095-01-31 team 2 admission note...</td>\n",
       "      <td>levofloxacin,lopressor,sotalol,prednisone,iron...</td>\n",
       "      <td>1970</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>395-02</td>\n",
       "      <td>record date: 2106-05-02 slhc emergency dept v...</td>\n",
       "      <td>prednisone,antibiotics,enoxaparin</td>\n",
       "      <td>518</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>396-03</td>\n",
       "      <td>record date: 2078-10-25 chief complaint annua...</td>\n",
       "      <td>novolog,aspirin,insulin aspart 70/30,ascorbic ...</td>\n",
       "      <td>1264</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>398-01</td>\n",
       "      <td>record date: 2105-12-15 mr. bryan comes in to...</td>\n",
       "      <td>captopril,atenolol,aspirin,acetylsalicylic acid</td>\n",
       "      <td>313</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>399-02</td>\n",
       "      <td>record date: 2070-03-24 neurology clinic foll...</td>\n",
       "      <td>aspirin,trazodone,neurontin,dilaudid,elavil,an...</td>\n",
       "      <td>1274</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                               text  \\\n",
       "0     101-01   record date: 2079-05-12 mercy care center mer...   \n",
       "1     101-02   record date: 2079-06-23 mercy care center mer...   \n",
       "2     101-03   record date: 2079-08-11 mercy care center mer...   \n",
       "3     105-02   record date: 2147-03-11 reason for consult: 6...   \n",
       "4     106-01   record date: 2083-11-17 northwest iowa health...   \n",
       "..       ...                                                ...   \n",
       "345   394-04   record date: 2095-01-31 team 2 admission note...   \n",
       "346   395-02   record date: 2106-05-02 slhc emergency dept v...   \n",
       "347   396-03   record date: 2078-10-25 chief complaint annua...   \n",
       "348   398-01   record date: 2105-12-15 mr. bryan comes in to...   \n",
       "349   399-02   record date: 2070-03-24 neurology clinic foll...   \n",
       "\n",
       "                                              entities  tokenizer_length_text  \\\n",
       "0                                    lipitor,synthroid                    593   \n",
       "1                         atenolol,hydrochlorothiazide                    442   \n",
       "2    atenolol,ramipril,lipitor,long acting nitrate,...                    608   \n",
       "3    lovastatin,fludrocortisone,celexa,proamatine,u...                   1021   \n",
       "4    vioxx,advil,ativan,zestril,diabetes medication...                    754   \n",
       "..                                                 ...                    ...   \n",
       "345  levofloxacin,lopressor,sotalol,prednisone,iron...                   1970   \n",
       "346                  prednisone,antibiotics,enoxaparin                    518   \n",
       "347  novolog,aspirin,insulin aspart 70/30,ascorbic ...                   1264   \n",
       "348    captopril,atenolol,aspirin,acetylsalicylic acid                    313   \n",
       "349  aspirin,trazodone,neurontin,dilaudid,elavil,an...                   1274   \n",
       "\n",
       "     tokenizer_length_entites  \n",
       "0                           6  \n",
       "1                          10  \n",
       "2                          41  \n",
       "3                          34  \n",
       "4                          21  \n",
       "..                        ...  \n",
       "345                       113  \n",
       "346                        12  \n",
       "347                       103  \n",
       "348                        18  \n",
       "349                        74  \n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenizer_length_entities'] = df.apply(lambda row: len(tokenizer.encode(str(row['entities']))) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>tokenizer_length_text</th>\n",
       "      <th>tokenizer_length_entites</th>\n",
       "      <th>tokenizer_length_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>299-05</td>\n",
       "      <td>record date: 2064-08-11 dcgh cancer center di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>258-04</td>\n",
       "      <td>record date: 2069-04-15 edvisit^49921666^schw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>182-02</td>\n",
       "      <td>record date: 2128-04-08 name: doherty, daniel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>183-02</td>\n",
       "      <td>record date: 2093-01-18 january 18, 2093 edwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>366-01</td>\n",
       "      <td>record date: 2059-08-07 pcc emergency dept vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>341-04</td>\n",
       "      <td>record date: 2097-12-15 sections of this note...</td>\n",
       "      <td>anticoagulation,steroids,ivf,morphine,coumadin...</td>\n",
       "      <td>2883</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>371-05</td>\n",
       "      <td>record date: 2080-05-27 71f w/ mmps returns t...</td>\n",
       "      <td>lidoderm,oxycodone,carvedilol,diovan,hydrochlo...</td>\n",
       "      <td>1665</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>341-05</td>\n",
       "      <td>record date: 2098-08-03 internal medicine g i...</td>\n",
       "      <td>coumadin,vanc,ctx,clonidine,insulin glargine,m...</td>\n",
       "      <td>1968</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>191-02</td>\n",
       "      <td>record date: 2094-03-19 gsh internal medicine...</td>\n",
       "      <td>rifampin,bactrim,o2,zofran,vanco,clinda,ns,nph...</td>\n",
       "      <td>2836</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>371-04</td>\n",
       "      <td>record date: 2079-10-02 71f w/ multiple medic...</td>\n",
       "      <td>narcotics,zantac,ranitidine hcl,percocet,ativa...</td>\n",
       "      <td>1829</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                               text  \\\n",
       "241   299-05   record date: 2064-08-11 dcgh cancer center di...   \n",
       "189   258-04   record date: 2069-04-15 edvisit^49921666^schw...   \n",
       "101   182-02   record date: 2128-04-08 name: doherty, daniel...   \n",
       "105   183-02   record date: 2093-01-18 january 18, 2093 edwa...   \n",
       "316   366-01   record date: 2059-08-07 pcc emergency dept vi...   \n",
       "..       ...                                                ...   \n",
       "288   341-04   record date: 2097-12-15 sections of this note...   \n",
       "324   371-05   record date: 2080-05-27 71f w/ mmps returns t...   \n",
       "289   341-05   record date: 2098-08-03 internal medicine g i...   \n",
       "112   191-02   record date: 2094-03-19 gsh internal medicine...   \n",
       "323   371-04   record date: 2079-10-02 71f w/ multiple medic...   \n",
       "\n",
       "                                              entities  tokenizer_length_text  \\\n",
       "241                                                NaN                    406   \n",
       "189                                                NaN                    525   \n",
       "101                                                NaN                    600   \n",
       "105                                                NaN                    499   \n",
       "316                                                NaN                    530   \n",
       "..                                                 ...                    ...   \n",
       "288  anticoagulation,steroids,ivf,morphine,coumadin...                   2883   \n",
       "324  lidoderm,oxycodone,carvedilol,diovan,hydrochlo...                   1665   \n",
       "289  coumadin,vanc,ctx,clonidine,insulin glargine,m...                   1968   \n",
       "112  rifampin,bactrim,o2,zofran,vanco,clinda,ns,nph...                   2836   \n",
       "323  narcotics,zantac,ranitidine hcl,percocet,ativa...                   1829   \n",
       "\n",
       "     tokenizer_length_entites  tokenizer_length_entities  \n",
       "241                         1                          1  \n",
       "189                         1                          1  \n",
       "101                         1                          1  \n",
       "105                         1                          1  \n",
       "316                         1                          1  \n",
       "..                        ...                        ...  \n",
       "288                       226                        226  \n",
       "324                       234                        234  \n",
       "289                       236                        236  \n",
       "112                       242                        242  \n",
       "323                       243                        243  \n",
       "\n",
       "[350 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('tokenizer_length_entities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'narcotics,zantac,ranitidine hcl,percocet,ativan,naproxen,nexium,lasix,furosemide,hydrochlorothiazide,levothyroxine sodium,loratadine,diovan,plavix,lipitor,carvedilol,oxycodone,penicillins,hctz,metfromin,estrogen,ibuprofen,caltrate and d,oxycodone+apap,lorazepam,miralax,polyethylene glycol,estrace,estradiol,esomeprazole,colace,docusate sodium,neurontin,gabapentin,fosamax,alendronate,valsartan,clopidogrel,metformin,calcium + d,calcium carbonate 1250 mg (500mg elem ca)/ vit d 200 iu,senna,sennosides,atorvastatin,corticosteroids,gadolinium chelates,gadolinuim,gadolinium chealtes'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[323, 'entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts bigger than 1024: 0.40285714285714286\n",
      "texts smaller than 1024: 0.5942857142857143\n"
     ]
    }
   ],
   "source": [
    "print('texts bigger than 1024:', len(df.loc[df['tokenizer_length']>1024])/len(df))\n",
    "print('texts smaller than 1024:', len(df.loc[df['tokenizer_length']<1024])/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts bigger than 2024: 72\n"
     ]
    }
   ],
   "source": [
    "print('texts bigger than 2024:', len(df.loc[df['tokenizer_length']>1500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitted with spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    for iter in range(10):\n",
    "      text = text.replace('\\n\\n', '\\n').replace('\\n ', '\\n').replace(' \\n', '\\n').replace('\\t', ' ')\n",
    "    text_filtered = ''\n",
    "    for char_index, char in enumerate(text):\n",
    "        if char_index < (len(text)-1):\n",
    "            if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "                text_filtered += char\n",
    "    return text_filtered.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [13:10,  2.26s/it]\n",
      "50it [01:56,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset_type in dataset_types:\n",
    "    filenames = next(walk(my_paths[dataset_type]), (None, None, []))[2]\n",
    "    # print(filenames[:20])\n",
    "    filenames_ann = [filename for filename in filenames if 'ann' in filename]\n",
    "    filenames_txt = [filename for filename in filenames if 'txt' in filename]\n",
    "    filenames_ann.sort()\n",
    "    filenames_txt.sort()\n",
    "    filenames_ann_txt = list(zip(filenames_ann, filenames_txt))\n",
    "\n",
    "    df_entities = pd.DataFrame()\n",
    "    df_dataset = pd.DataFrame()\n",
    "    for index, (filename_ann, filename_txt) in tqdm(enumerate(filenames_ann_txt)):\n",
    "        # print('Current index:', index)value\n",
    "        df_ann = pd.read_csv(my_paths[dataset_type] + filename_ann, sep='\\t', names=['entity-event-context', 'classification-type', 'value'])\n",
    "        df_entities = pd.DataFrame()\n",
    "        # print(filename_ann)\n",
    "        if (df_ann.apply(lambda row: row['value'] if row['entity-event-context'][0]== 'T' else '', axis=1).shape[0] > 0):\n",
    "            df_entities['entities'] = df_ann.apply(lambda row: row['value'].lower() if row['entity-event-context'][0]== 'T' else '', axis=1)\n",
    "            df_entities = df_entities[df_entities['entities'] != '']\n",
    "            df_entities = df_entities.drop_duplicates(['entities'])\n",
    "            entities =  ','.join(df_entities.entities)\n",
    "        else:\n",
    "            entities = ''\n",
    "\n",
    "        with open(my_paths[dataset_type] + filename_txt, 'r') as file:\n",
    "            text = ''.join(file.readlines())\n",
    "\n",
    "        # text = ''.join(text).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        # text_filtered = ''\n",
    "        # for char_index, char in enumerate(text):\n",
    "        #     if char_index < (len(text)-1):\n",
    "        #         if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "        #             text_filtered += char\n",
    "        # text_filtered = text_filtered.lower()\n",
    "        doc = nlp(text)\n",
    "        max_lenght = 400\n",
    "        text_slices = []\n",
    "        sent_index = 0\n",
    "        sents = [text_preprocess(sent.text) for sent in doc.sents]\n",
    "        text_slice = ''\n",
    "        for sent in sents:\n",
    "            if len(tokenizer.encode(text_slice + sent)) > max_lenght:\n",
    "                text_slices.append(text_slice)\n",
    "                text_slice = sent\n",
    "            else:\n",
    "                text_slice += sent\n",
    "        text_slices.append(text_slice)\n",
    "\n",
    "        # print(entities)\n",
    "\n",
    "        for sliced_text in  text_slices:\n",
    "            filtered_entities = [entity for entity in entities.split(',') if entity in sliced_text]\n",
    "            if len(filtered_entities) > 0:\n",
    "                filtered_entities = ','.join(filtered_entities)\n",
    "            else:\n",
    "                filtered_entities = ''\n",
    "            # filtered_entities = \n",
    "            row = pd.DataFrame({ 'filename': filename_ann[:-4], 'text':  sliced_text, 'entities': [filtered_entities] })\n",
    "            df_dataset = pd.concat([df_dataset, row])\n",
    "    df_dataset.to_csv('../data/trainingdata_v3/' + 'datasets/' + dataset_type + '_text_splitted'+ str(max_lenght) +'_entities.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nrecord date: 2091-11-22\\n57 yo wf\\ncc:\\nhtn; tolerating toprol 150 mg/d, and lisinopril 20 mg\\nhbpm about 145 sys and about 90 diastolic\\nhx', ' htn found 10/89\\npmhx htn\\ndm 2,\\nhlp\\nhypothyroidism\\nmeds\\nmedications\\nlisinopril 20 mg, 1 tablet(s) po qd : take as directed did not tak', '\\ndyazide 1 capsule 50/25 po qd : take as directed\\nlevothyroxine sodium 50mcg, 1 tablet(s) po qd : take as directed\\nlipitor (atorvastatin) 20mg, 1 tablet(s) po qd : take 1 hour post supper or at bed time\\nasa (children 81mg, 1 tablet(s) qd : take as directed\\ntoprol xl (metoprolol succinate extended release) 100mg, 1.5 tablet(s) po qd', 'al', 'pnc ras', '\\nfhx\\ncad m ca no endo m with dm', 'sh', '\\ntobacco neg etoh neg drugs neg', 'wor', ' detective marital div 1 c dom violence neg belts no/ advised to use seatbelts.', 'ros\\nvision n', ' hearing nl fever neg\\nheadache neg weakness neg numbness neg seizures neg\\nchest pain neg', 'palpitatio', 'ne', ' syncope neg\\ndyspnea neg wheezing neg cough neg coryza neg\\nnausea neg vomit neg diarrhea neg constipation neg weight loss gain abdominal pain neg', 'nocturi', '1-2 dysuria neg polidypsia neg paresthesias neg tiredness neg hoarsness neg heat intolerance neg', 'col', 'intoleranc', 'ne', '\\nmenses hysterctomy 2064 for endometriosis', ' libido nl impotence neg\\narthralgia neg back pain neg\\nbleeding neg nodes no enlarg\\nrash neg pruritus neg hair loss neg', 'hirsutis', 'ne', '\\ntetanus tox pneumovax influenza mmr', 'pp', '\\nsexual behavior n', ' std neg hiv neg hepatitis neg\\ndiet nl mets 3 cholesterol\\npex bp 160/100 hbpm as above', 'h', \" 72 rr 16 wt 247 lbs\\npt at gold's gym.\", 'neur', ' mental status n', ' dtr nl gait nl motor nl sensory nl\\nneck jvd no carotids/bruits no nodes neg', 'thyroi', ' wnl\\nchest wheezes n', '\\ncor sounds s1 s2 n', ' murmurs n', '\\nabdomen soft nt masses no obese no bruits', 'extremitie', ' edema no dtr normal', '\\n \\na+p\\nhtn bphigh even by hbpm; p: increase lisinopril 40 mg/d\\ntype 2 dm on diet; p: continue diet and lose wt\\nhlp on lipitor,and diet; p: continue same', '\\nhypothyroidism clinically euthyr; tsh high; p; continue levothyroxine.', 'lvh by ekg; p: control bp.', 'all pnc', '\\nadvised to make appt with ophthalm.\\nfu 1 month', '']\n",
      "['\\n\\n\\nRecord date: 2091-11-22\\n\\n57 yo wf\\n\\n\\n\\nCC: \\n\\n\\n\\nHTN; tolerating toprol 150 mg/d, and lisinopril 20 mg\\n\\n\\n\\nHBPM about 145  sys and about 90 diastolic\\n\\n\\n\\nHx:', ' htn found 10/89\\n\\n\\n\\nPMHx HTN\\n\\n  DM 2,\\n\\n  HLP\\n\\n   hypothyroidism\\n\\n\\n\\nMeds \\n\\nMedications\\n\\nLISINOPRIL 20 MG, 1 Tablet(s) PO QD : Take as directed did not take', '\\n\\nDYAZIDE 1 CAPSULE 50/25 PO QD : Take as directed \\n\\nLevothyroxine Sodium 50MCG, 1 Tablet(s) PO QD : Take as directed \\n\\nLipitor (ATORVASTATIN) 20MG, 1 Tablet(s) PO QD : Take 1 hour post supper or at bed time\\n\\nAsa (CHILDREN 81MG, 1 Tablet(s) QD : Take as directed \\n\\nToprol Xl (METOPROLOL Succinate Extended Release) 100MG, 1.5 Tablet(s) PO QD \\n\\n\\n\\n\\n\\n', 'ALL', 'PNC rash', '\\n\\n\\n\\nFHx\\n\\nCAD   M                       Ca      no                         Endo  M with DM\\n\\n\\n\\n', 'SHx', '\\n\\ntobacco     neg      ETOH    neg     drugs neg     ', 'work', ' detective         marital   div 1 c          dom violence neg     belts  no/ advised to use seatbelts.     \\n\\n\\n\\n', 'ROS\\n\\nvision nl', '                     hearing nl                    fever neg\\n\\nheadache neg             weakness neg             numbness neg               seizures neg\\n\\nchest pain neg            ', 'palpitation', 'neg', '            syncope neg\\n\\ndyspnea neg               wheezing neg              cough neg                     coryza neg\\n\\nnausea neg                 vomit neg                    diarrhea neg                  constipation neg       weight loss gain abdominal pain neg\\n\\n', 'nocturia', '1-2              dysuria neg                 polidypsia neg                paresthesias neg      tiredness neg             hoarsness neg             heat intolerance neg       ', 'cold', 'intolerance', 'neg', '\\n\\nmenses hysterctomy 2064 for endometriosis.', '              libido nl                        impotence neg\\n\\narthralgia neg            back pain neg\\n\\nbleeding neg             nodes no enlarg\\n\\nrash neg                   pruritus neg                  hair loss neg                  ', 'hirsutism', 'neg', '\\n\\ntetanus tox               pneumovax                   influenza                       MMR             ', 'PPD', '\\n\\nsexual behavior nl', '    STD neg                       HIV neg                         hepatitis neg\\n\\ndiet nl                      METS  3                        cholesterol\\n\\n\\n\\nPEx         BP   160/100    HBPM    as above        ', 'HR', \" 72               RR   16            wt 247  lbs \\n\\npt at gold's gym. \\n\\n\", 'NEURO', '       mental status nl', '         DTR  nl          gait nl            motor nl           sensory nl\\n\\nNECK           jvd   no        carotids/bruits  no         nodes  neg     ', 'thyroid', ' wnl\\n\\nCHEST         wheezes no', '\\n\\nCOR             sounds S1 S2 nl', '        murmurs no', '\\n\\nABDOMEN soft NT              masses no            obese   no bruits \\n\\n', 'EXTREMITIES', '  edema no     DTR normal.', '\\n\\n                                      \\n\\nA+P\\n\\n\\n\\nHTN BPhigh even by HBPM;  P:   increase lisinopril 40 mg/d\\n\\nType 2 dm on diet; P: continue diet and lose wt\\n\\nHLP on lipitor,and diet; P: continue same.', '\\n\\nHypothyroidism clinically euthyr; TSH high; P; continue levothyroxine.\\n\\n', 'LVH by ekg; P: control BP.\\n\\n', 'All PNC.', '\\n\\n\\n\\nadvised to make appt with ophthalm.\\n\\nFU  1 month.', '\\n\\n\\n\\n\\n\\n\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/trainingdata_v3/train/' + '359-02.txt', 'r') as file:\n",
    "    text = ''.join(file.readlines())\n",
    "\n",
    "# text = ''.join(text).replace('\\n', ' ').replace('\\t', ' ')\n",
    "# text_filtered = ''\n",
    "# for char_index, char in enumerate(text):\n",
    "#     if char_index < (len(text)-1):\n",
    "#         if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "#             text_filtered += char\n",
    "# text_filtered = text_filtered.lower()\n",
    "# print(text)\n",
    "doc = nlp(text)\n",
    "max_lenght = 100\n",
    "text_ids_slices = []\n",
    "sent_index = 0\n",
    "sents = [text_preprocess(sent.text) for sent in doc.sents]\n",
    "text_slice = ''\n",
    "for sent in sents:\n",
    "    if len(tokenizer.encode(text_slice + sent)) > max_lenght:\n",
    "        text_ids_slices.append(tokenizer.encode(text_slice))\n",
    "        text_slice = sent\n",
    "    else:\n",
    "        text_slice += sent\n",
    "text_ids_slices.append(tokenizer.encode(text_slice))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prova = pd.read_csv('../data/trainingdata_v3/' + 'datasets/train_text_splitted750_entities.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>101-01</td>\n",
       "      <td>\\nrecord date: 2079-05-12\\nmercy care center\\n...</td>\n",
       "      <td>lipitor,synthroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101-02</td>\n",
       "      <td>\\nrecord date: 2079-06-23\\nmercy care center\\n...</td>\n",
       "      <td>atenolol,hydrochlorothiazide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>101-03</td>\n",
       "      <td>\\nrecord date: 2079-08-11mercy care cente\\nmer...</td>\n",
       "      <td>atenolol,ramipril,lipitor,long acting nitrate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>105-02</td>\n",
       "      <td>\\nrecord date: 2147-03-11\\nreason for consult:...</td>\n",
       "      <td>lovastatin,fludrocortisone,celexa,proamatine,u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>105-02</td>\n",
       "      <td>mr. tuttle is a 65 year old male with a three ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0</td>\n",
       "      <td>396-03</td>\n",
       "      <td>\\nrecord date: 2078-10-25chief complain\\nannua...</td>\n",
       "      <td>novolog,aspirin,insulin aspart 70/30,ascorbic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0</td>\n",
       "      <td>396-03</td>\n",
       "      <td>\\ngu: no dysuria, hematuria.\\nlmp: late 40s\\nc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>398-01</td>\n",
       "      <td>\\nrecord date: 2105-12-15mr. bryan comes in to...</td>\n",
       "      <td>captopril,aspirin,acetylsalicylic acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0</td>\n",
       "      <td>399-02</td>\n",
       "      <td>\\nrecord date: 2070-03-24\\nneurology clinic fo...</td>\n",
       "      <td>aspirin,trazodone,neurontin,dilaudid,antibiotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>399-02</td>\n",
       "      <td>\\npmhx:\\n-stroke as above\\n-htn\\n-hyperlipidem...</td>\n",
       "      <td>aspirin,trazodone,neurontin,elavil,zestril,ava...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 filename                                               text  \\\n",
       "0             0   101-01  \\nrecord date: 2079-05-12\\nmercy care center\\n...   \n",
       "1             0   101-02  \\nrecord date: 2079-06-23\\nmercy care center\\n...   \n",
       "2             0   101-03  \\nrecord date: 2079-08-11mercy care cente\\nmer...   \n",
       "3             0   105-02  \\nrecord date: 2147-03-11\\nreason for consult:...   \n",
       "4             0   105-02  mr. tuttle is a 65 year old male with a three ...   \n",
       "..          ...      ...                                                ...   \n",
       "691           0   396-03  \\nrecord date: 2078-10-25chief complain\\nannua...   \n",
       "692           0   396-03  \\ngu: no dysuria, hematuria.\\nlmp: late 40s\\nc...   \n",
       "693           0   398-01  \\nrecord date: 2105-12-15mr. bryan comes in to...   \n",
       "694           0   399-02  \\nrecord date: 2070-03-24\\nneurology clinic fo...   \n",
       "695           0   399-02  \\npmhx:\\n-stroke as above\\n-htn\\n-hyperlipidem...   \n",
       "\n",
       "                                              entities  \n",
       "0                                    lipitor,synthroid  \n",
       "1                         atenolol,hydrochlorothiazide  \n",
       "2    atenolol,ramipril,lipitor,long acting nitrate,...  \n",
       "3    lovastatin,fludrocortisone,celexa,proamatine,u...  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "691  novolog,aspirin,insulin aspart 70/30,ascorbic ...  \n",
       "692                                                NaN  \n",
       "693             captopril,aspirin,acetylsalicylic acid  \n",
       "694   aspirin,trazodone,neurontin,dilaudid,antibiotics  \n",
       "695  aspirin,trazodone,neurontin,elavil,zestril,ava...  \n",
       "\n",
       "[696 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrecord date: 2091-11-22\\n57 yo wf\\ncc:\\nhtn; tolerating toprol 150 mg/d, and lisinopril 20 mg\\nhbpm about 145 sys and about 90 diastolic\\nhx'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(text_ids_slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' htn found 10/89\\npmhx htn\\ndm 2,\\nhlp\\nhypothyroidism\\nmeds\\nmedications\\nlisinopril 20 mg, 1 tablet(s) po qd : take as directed did not tak'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(text_ids_slices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/trainingdata_v3/train/' + 'train' + '_text_splitted_entities.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitted every N tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [00:06, 57.32it/s]\n",
      "50it [00:00, 52.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for dataset_type in dataset_types:\n",
    "    filenames = next(walk(my_paths[dataset_type]), (None, None, []))[2]\n",
    "    # print(filenames[:20])\n",
    "    filenames_ann = [filename for filename in filenames if 'ann' in filename]\n",
    "    filenames_txt = [filename for filename in filenames if 'txt' in filename]\n",
    "    filenames_ann.sort()\n",
    "    filenames_txt.sort()\n",
    "    filenames_ann_txt = list(zip(filenames_ann, filenames_txt))\n",
    "\n",
    "    df_entities = pd.DataFrame()\n",
    "    df_dataset = pd.DataFrame()\n",
    "    for index, (filename_ann, filename_txt) in tqdm(enumerate(filenames_ann_txt)):\n",
    "        # print('Current index:', index)value\n",
    "        df_ann = pd.read_csv(my_paths[dataset_type] + filename_ann, sep='\\t', names=['entity-event-context', 'classification-type', 'value'])\n",
    "        df_entities = pd.DataFrame()\n",
    "        # print(filename_ann)\n",
    "        if (df_ann.apply(lambda row: row['value'] if row['entity-event-context'][0]== 'T' else '', axis=1).shape[0] > 0):\n",
    "            df_entities['entities'] = df_ann.apply(lambda row: row['value'].lower() if row['entity-event-context'][0]== 'T' else '', axis=1)\n",
    "            df_entities = df_entities[df_entities['entities'] != '']\n",
    "            df_entities = df_entities.drop_duplicates(['entities'])\n",
    "            entities =  ','.join(df_entities.entities)\n",
    "        else:\n",
    "            entities = ''\n",
    "\n",
    "        with open(my_paths[dataset_type] + filename_txt, 'r') as file:\n",
    "            text = file.readlines()\n",
    "\n",
    "        text = ''.join(text).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        text_filtered = ''\n",
    "        for char_index, char in enumerate(text):\n",
    "            if char_index < (len(text)-1):\n",
    "                if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "                    text_filtered += char\n",
    "        text_filtered = text_filtered.lower()\n",
    "\n",
    "        text_filtered_ids = tokenizer.encode(text_filtered)\n",
    "        text_slices = []\n",
    "        start_slice = 0\n",
    "        max_lenght = 750\n",
    "        for end_slice in range(max_lenght, len(text_filtered_ids), max_lenght):\n",
    "            text_slices.append([start_slice, end_slice])\n",
    "            start_slice = end_slice\n",
    "        text_slices.append([start_slice, len(text_filtered_ids)])\n",
    "\n",
    "        # print(entities)\n",
    "\n",
    "        for start, end in  text_slices:\n",
    "            sliced_text =  tokenizer.decode(text_filtered_ids[start:end])\n",
    "            filtered_entities = [entity for entity in entities.split(',') if entity in sliced_text]\n",
    "            if len(filtered_entities) > 0:\n",
    "                filtered_entities = ','.join(filtered_entities)\n",
    "            else:\n",
    "                filtered_entities = ''\n",
    "            # filtered_entities = \n",
    "            row = pd.DataFrame({ 'filename': filename_ann[:-4], 'text':  sliced_text, 'entities': [filtered_entities] })\n",
    "            df_dataset = pd.concat([df_dataset, row])\n",
    "    df_dataset.to_csv('../data/trainingdata_v3/datasets/' + dataset_type + '_text_splitted750_entities2.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_type in dataset_types:\n",
    "    filenames = next(walk(my_paths[dataset_type]), (None, None, []))[2]\n",
    "    # print(filenames[:20])\n",
    "    filenames_ann = [filename for filename in filenames if 'ann' in filename]\n",
    "    filenames_txt = [filename for filename in filenames if 'txt' in filename]\n",
    "    filenames_ann.sort()\n",
    "    filenames_txt.sort()\n",
    "    filenames_ann_txt = list(zip(filenames_ann, filenames_txt))\n",
    "\n",
    "    df_dataset = pd.DataFrame()\n",
    "    for index, (filename_ann, filename_txt) in enumerate(filenames_ann_txt):\n",
    "        with open(my_paths[dataset_type] + filename_txt, 'r') as file:\n",
    "            text = file.readlines()\n",
    "        text = ''.join(text).replace('\\n', ' ').replace('\\t', ' ')\n",
    "        text_filtered = ''\n",
    "        for char_index, char in enumerate(text):\n",
    "            if char_index < (len(text)-1):\n",
    "                if not(text[char_index + 1] == ' ' and char == ' '):\n",
    "                    text_filtered += char\n",
    "        text_filtered = text_filtered.lower()\n",
    "        # print('Current index:', index)value\n",
    "        df_ann = pd.read_csv(my_paths[dataset_type] + filename_ann, sep='\\t', names=['entity-event-context', 'classification-type', 'value'])\n",
    "        df_entities = pd.DataFrame()\n",
    "\n",
    "        # print(filename_ann)\n",
    "        if (df_ann.apply(lambda row: row['value'] if row['entity-event-context'][0]== 'T' else '', axis=1).shape[0] > 0):\n",
    "            df_entities['entity'] = df_ann.apply(lambda row: row['value'].lower() if row['entity-event-context'][0]== 'T' else '', axis=1)\n",
    "            df_entities['disposition'] = df_ann.apply(lambda row: row['classification-type'].lower().split(' ')[0] if row['entity-event-context'][0]== 'T' else '', axis=1)\n",
    "            df_entities = df_entities[df_entities['entity'] != '']\n",
    "            df_entities = df_entities.drop_duplicates(['entity'])\n",
    "            df_entities['filename'] = filename_ann[:-4]\n",
    "            df_entities['text'] = text_filtered\n",
    "            entitites =  ','.join(df_entities.entity)\n",
    "            df_entities['output'] = df_entities.apply(lambda row: 'medication: ' + str(row['entity']) + '<SEPO>' + 'disposition: ' + str(row['disposition']), axis=1)\n",
    "            df_entities = df_entities[['filename', 'text', 'output']]\n",
    "        else:\n",
    "            entitites = ''\n",
    "        row = pd.DataFrame({ 'filename': filename_ann[:-4], 'text': [text_filtered], 'output': ['medication_list: ' + entitites]})\n",
    "        df_dataset = pd.concat([df_dataset, df_entities, row], ignore_index=True)\n",
    "    #     df_dataset = pd.concat([df_dataset, row], ignore_index=True)\n",
    "\n",
    "    # # print(df_dataset.head())\n",
    "    df_dataset.to_csv(my_paths[dataset_type] + dataset_type + '_entities_disposition.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-01</td>\n",
       "      <td>record date: 2106-02-12 campbell orthopedic a...</td>\n",
       "      <td>medication: prozac&lt;SEPO&gt;disposition: nodisposi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-01</td>\n",
       "      <td>record date: 2106-02-12 campbell orthopedic a...</td>\n",
       "      <td>medication: cardizem&lt;SEPO&gt;disposition: nodispo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100-01</td>\n",
       "      <td>record date: 2106-02-12 campbell orthopedic a...</td>\n",
       "      <td>medication: amaryl&lt;SEPO&gt;disposition: nodisposi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100-01</td>\n",
       "      <td>record date: 2106-02-12 campbell orthopedic a...</td>\n",
       "      <td>medication: glucophage&lt;SEPO&gt;disposition: nodis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100-01</td>\n",
       "      <td>record date: 2106-02-12 campbell orthopedic a...</td>\n",
       "      <td>medication_list: prozac,cardizem,amaryl,glucop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>397-03</td>\n",
       "      <td>record date: 2076-09-21 patient name: goldber...</td>\n",
       "      <td>medication: glyburide&lt;SEPO&gt;disposition: nodisp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>397-03</td>\n",
       "      <td>record date: 2076-09-21 patient name: goldber...</td>\n",
       "      <td>medication: codeine&lt;SEPO&gt;disposition: nodispos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>397-03</td>\n",
       "      <td>record date: 2076-09-21 patient name: goldber...</td>\n",
       "      <td>medication: ms contin&lt;SEPO&gt;disposition: nodisp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>397-03</td>\n",
       "      <td>record date: 2076-09-21 patient name: goldber...</td>\n",
       "      <td>medication: unasyn&lt;SEPO&gt;disposition: undetermined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>397-03</td>\n",
       "      <td>record date: 2076-09-21 patient name: goldber...</td>\n",
       "      <td>medication_list: lipitor,neurontin,plavix,zest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                               text  \\\n",
       "0     100-01   record date: 2106-02-12 campbell orthopedic a...   \n",
       "1     100-01   record date: 2106-02-12 campbell orthopedic a...   \n",
       "2     100-01   record date: 2106-02-12 campbell orthopedic a...   \n",
       "3     100-01   record date: 2106-02-12 campbell orthopedic a...   \n",
       "4     100-01   record date: 2106-02-12 campbell orthopedic a...   \n",
       "..       ...                                                ...   \n",
       "793   397-03   record date: 2076-09-21 patient name: goldber...   \n",
       "794   397-03   record date: 2076-09-21 patient name: goldber...   \n",
       "795   397-03   record date: 2076-09-21 patient name: goldber...   \n",
       "796   397-03   record date: 2076-09-21 patient name: goldber...   \n",
       "797   397-03   record date: 2076-09-21 patient name: goldber...   \n",
       "\n",
       "                                                output  \n",
       "0    medication: prozac<SEPO>disposition: nodisposi...  \n",
       "1    medication: cardizem<SEPO>disposition: nodispo...  \n",
       "2    medication: amaryl<SEPO>disposition: nodisposi...  \n",
       "3    medication: glucophage<SEPO>disposition: nodis...  \n",
       "4    medication_list: prozac,cardizem,amaryl,glucop...  \n",
       "..                                                 ...  \n",
       "793  medication: glyburide<SEPO>disposition: nodisp...  \n",
       "794  medication: codeine<SEPO>disposition: nodispos...  \n",
       "795  medication: ms contin<SEPO>disposition: nodisp...  \n",
       "796  medication: unasyn<SEPO>disposition: undetermined  \n",
       "797  medication_list: lipitor,neurontin,plavix,zest...  \n",
       "\n",
       "[798 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['output'] = df_dataset.apply(lambda row: row['medication: ' + row['entity'] + '<SEPO>' + 'disposition: ' + row['disposition']], axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b4ae32079e0bf426878f2104226b4c202dc5dd07bf66a8fad266fc6f7ab6329"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
