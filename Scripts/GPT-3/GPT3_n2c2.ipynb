{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca169619-e643-45a4-8d66-de9b275a3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29990126-37d7-4aea-8017-bfe3377f559d",
   "metadata": {},
   "source": [
    "# Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797df48d-d8d3-4d8c-9495-b0f0aebf850c",
   "metadata": {},
   "source": [
    "This script works as follows:\n",
    "- Gets the reference text that contains examples to \"teach\" GPT-3\n",
    "- Gets the text of a single document and splits it into paragraphs\n",
    "- Combine reference text with every single paragraph to get the prompt\n",
    "- Invokes GPT-3 to produce outputs from prompt\n",
    "- Combines all outputs to get the output for the entire file in the \"smart\" format\n",
    "- Converts the file in the brat format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355234e-4089-4124-b6a8-66051aead84a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad2d9a-c0b2-4307-b848-133b272e8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import openai\n",
    "import re\n",
    "import textwrap\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43d6ce-25b6-4e05-bafd-59020380191f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f46fd-4381-4b53-85ef-2f0427c98d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findnth(s, subs, n):\n",
    "    parts = s.split(subs, n + 1)\n",
    "    if len(parts) <= n + 1:\n",
    "        return -1\n",
    "    return len(s) - len(parts[-1]) - len(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d3478-825c-40a9-8eb8-ed3148c5a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_output(simplified_out, document, remove_until, drug_list, filter_by_drug_list = False):\n",
    "    '''\n",
    "    Starts from the \"simplified\" output, i.e. Drug and information related, and converts it into brat format.\n",
    "    Example:\n",
    "    Input\n",
    "    \"DRUG: hydrochlorothiazide, DISPOSITION: change, CERTAINTY: certain, ACTOR: physician, ACTION: stop, TEMPORALITY: present, NEGATION: no\"\n",
    "    Output:\n",
    "    \"T8\tDisposition 1780 1799\thydrochlorothiazide\n",
    "    E8\tDisposition:T8 \n",
    "    A26\tCertainty E8 Certain\n",
    "    A27\tActor E8 Physician\n",
    "    A28\tAction E8 Stop\n",
    "    A29\tTemporality E8 Present\n",
    "    A33\tNegation E8 NotNegated\"\n",
    "    Parameters:\n",
    "    - simplified output: string with the simplified output\n",
    "    - document: string with text of whole document\n",
    "    - remove_until: num of characters removed by the beginning of document. This is used to compensate if the header is removed\n",
    "    - drug_list: list of drugs used to filter the revealed entities. This is done only if filter_by_drug_list = True\n",
    "    '''\n",
    "    # remove_until: to compensate for header removed at beginning\n",
    "    lines_total = simplified_out.strip().split('DRUG: ')\n",
    "    lines_unfiltered = [i for i in lines_total if i != '']\n",
    "    \n",
    "    # Filter by external drug list\n",
    "    if filter_by_drug_list:\n",
    "        lines = []\n",
    "        for el in lines_unfiltered:\n",
    "            drug_name = el.split(',')[0].lower()\n",
    "            if drug_name in drug_list:\n",
    "                lines.append(el)\n",
    "    else:\n",
    "        lines = lines_unfiltered\n",
    "    \n",
    "    drugs_count = {}\n",
    "    TE_count = 0\n",
    "    A_count = 0\n",
    "    output = ''\n",
    "    lines = [l for l in lines if len(l) > 0]\n",
    "    for l in lines:\n",
    "        fields = l.split(',')\n",
    "        name = fields[0]\n",
    "        drugs_count[name] = drugs_count.get(name, 0) + 1\n",
    "        start_pos = findnth(document, name, drugs_count[name] - 1)\n",
    "        end_pos = start_pos + len(name)\n",
    "        TE_count = TE_count + 1\n",
    "        disposition = re.search('DISPOSITION: ([^,]*),', l)\n",
    "        if disposition is not None:\n",
    "            disposition = disposition.group(1)\n",
    "        # if disposition is not None and disposition.lower() == 'yes':\n",
    "        if disposition is not None and disposition.lower() == 'change':\n",
    "            disposition_str = 'Disposition'\n",
    "        # elif disposition is not None and disposition.lower() == 'no':\n",
    "        elif disposition is not None and disposition.lower() == 'no change':\n",
    "            disposition_str = 'NoDisposition'\n",
    "        elif disposition is not None and disposition.lower() == 'undetermined':\n",
    "            disposition_str = 'Undetermined'\n",
    "        else:\n",
    "            disposition_str = DEFAULT_DISPOSITION\n",
    "        output = output + 'T' + str(TE_count) + '\\t' + disposition_str + ' ' + str(start_pos+remove_until) + ' ' + str(end_pos+remove_until) + '\\t' + name + '\\n'\n",
    "        output = output + 'E' + str(TE_count) + '\\t' + disposition_str +':' + 'T' + str(TE_count) +\t'\\n'\n",
    "        if disposition_str == 'Disposition':\n",
    "            for attr in DEFAULT_ATTRIBUTES.keys():\n",
    "                A_count = A_count + 1\n",
    "                model_value = re.search(attr + ': ([^,]*),', l)\n",
    "                if model_value is not None:\n",
    "                    model_value = model_value.group(1)\n",
    "                if attr == 'NEGATION' and model_value is not None:\n",
    "                    if model_value.lower() == 'yes':\n",
    "                        model_value = 'Negated'\n",
    "                    elif model_value.lower() == 'no':\n",
    "                        model_value = 'NotNegated'\n",
    "                if model_value is not None and model_value.title() in VALID_VALUES[attr]:\n",
    "                    value = model_value.title()\n",
    "                else:\n",
    "                    value = DEFAULT_ATTRIBUTES[attr].title()\n",
    "                output = output + 'A' + str(A_count) + '\\t' + attr.title() + ' E' + str(TE_count) + ' ' + value + '\\n'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782e2e0-00f0-40c8-949b-e01bd1a973f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_paragraphs(doc, simple_mode = True, num_chars = 200):\n",
    "    '''\n",
    "    Split a text into paragraph.\n",
    "    If simple_mode = True, paragraphs are strings with num_chars words.\n",
    "    If simple_mode = False, paragraphs will be split in a more proper way. #TODO\n",
    "    '''\n",
    "    paragraphs = []\n",
    "    if simple_mode: # Do simple splitting\n",
    "        paragraphs = textwrap.wrap(doc, num_chars)\n",
    "    else: # Do smart splitting\n",
    "        pass #TODO\n",
    "    \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63484454-72b0-430b-b82a-7eb487483494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paremeters\n",
    "VALID_VALUES = {'CERTAINTY': ['Certain', 'Hypothetical', 'Conditional', 'Unknown'],\n",
    "                'TEMPORALITY': ['Past', 'Present', 'Future', 'Unknown'], \n",
    "                'ACTOR': ['Physician', 'Patient', 'Unknown'], \n",
    "                'ACTION': ['Start', 'Stop', 'Increase', 'Decrease', 'OtherChange', 'UniqueDose', 'Unknown'], \n",
    "                'NEGATION': ['Negated', 'NotNegated']\n",
    "}\n",
    "\n",
    "# most common values in training set\n",
    "DEFAULT_ATTRIBUTES = {'CERTAINTY': 'Certain', 'TEMPORALITY': 'Past', 'ACTOR': 'Physician', 'ACTION': 'Start', 'NEGATION': 'NotNegated'}\n",
    "\n",
    "DEFAULT_DISPOSITION = 'NoDisposition'\n",
    "\n",
    "savepath = 'result_from_GPT3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526fd3d-f34f-4bf5-9751-1b47cfcd8401",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cda272-e882-461c-b56e-7cf9fb31055b",
   "metadata": {},
   "source": [
    "The prompt will be composed by:\n",
    "1. Examples = sentences followed by drugs formatted in the \"smart\" way. Example:\n",
    "\n",
    "\"INPUT:\n",
    "If Elavil is helpful, may increase to 50 qhs after one week of therapy.\n",
    "OUTPUT DRUGS WITH DETAILS:\n",
    "DRUG: Elavil, DISPOSITION: change, CERTAINTY: conditional, ACTOR: physician, ACTION: increase, TEMPORALITY: future, NEGATION: no\"\n",
    "\n",
    "2. \"INPUT\" + text of single paragraph + \"OUTPUT DRUGS WITH DETAILS:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d297bf4-b54c-4eea-a344-4a9cd9a2bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = # Path of .txt files to be evaluated\n",
    "\n",
    "# Reference file\n",
    "filename = # Path of the file with the \"gold\" prompt\n",
    "file = open(filename,mode='r')\n",
    "reference = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd37aa-7b8b-4894-aff8-7f2ff5377127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all txt files in folder\n",
    "txt_files = []\n",
    "for file in os.listdir(basepath):\n",
    "    if file.endswith('.txt'):\n",
    "        txt_files.append(os.path.join(basepath, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc15281-5a54-438f-a06d-0f19ccf7df30",
   "metadata": {},
   "source": [
    "# Get Drugs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34294fc-2dc9-4cb4-ba68-60b5a20f86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df = pd.read_csv('drugs.csv', sep=',')\n",
    "drug_df.rename(columns={'0': 'DrugName'}, inplace=True)\n",
    "drug_df.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "drug_df = drug_df['DrugName'].str.lower()\n",
    "drug_list = drug_df.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dca41e-6a8f-4c0d-a1dc-be4ee6f4a03e",
   "metadata": {},
   "source": [
    "# Invoke GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e46714-ca61-4623-be22-d7db1560968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Credentials\n",
    "openai.organization = # Organization API-key\n",
    "openai.api_key = # Personal API-key\n",
    "\n",
    "openai.Engine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fbe7e-db84-4fac-9297-ab66a8e6f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_slice_text = True # If True, splits text into paragraphs\n",
    "do_clean_text = False # If True, remove header and footer #TODO\n",
    "\n",
    "for filename in txt_files:\n",
    "    print(f'************************************ Working on {filename.split(\"/\")[-1]} ************************************')\n",
    "    \n",
    "    # Read file content\n",
    "    file = open(filename,mode='r')\n",
    "    input_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    # OPTIONAL: clean text from header and footer\n",
    "    if do_clean_text:\n",
    "        pass #TODO\n",
    "    else: # Do not perform cleaning\n",
    "        clean_text = input_text\n",
    "        remove_until = 0 # Num of chars removed by cutting off header\n",
    "    \n",
    "    # Slice text in smaller chunks\n",
    "    text_chunks = split_into_paragraphs(clean_text, simple_mode=True, num_chars=1000)\n",
    "    \n",
    "    response_chunk = []\n",
    "    for el in text_chunks:\n",
    "        # Produce prompt text\n",
    "        prompt_text = reference + '\\n\\nINPUT:\\n\\n' + el + '\\n\\nOUTPUT DRUGS WITH DETAILS:'\n",
    "        # Invoke GPT-3\n",
    "        response = openai.Completion.create(\n",
    "              engine=\"text-davinci-002\",\n",
    "              prompt=prompt_text,\n",
    "              temperature=0,\n",
    "              max_tokens=1000, # TODO Evaluate if there's a \"better\" value\n",
    "              # top_p=1,\n",
    "              # frequency_penalty=0.0,\n",
    "              # presence_penalty=0.0,\n",
    "              # stop=[\"\\n\"]\n",
    "            )\n",
    "        response_text = response['choices'][0]['text']\n",
    "        if ('no drugs mentioned' in response_text.lower()): # If response is \"No drugs mentioned\", do not append, it messes with the valuation script\n",
    "            pass\n",
    "        else:\n",
    "            response_chunk.append(response_text)\n",
    "    merged_response = '\\n'.join(response_chunk)\n",
    "    \n",
    "    # Convert to brat format\n",
    "    result = get_standard_output(merged_response.replace('\\n\\n\\n', '\\n', -1), clean_text, 0, drug_list=drug_list, filter_by_drug_list=True) # Sometime there are unnecessary new lines\n",
    "    # Write to file\n",
    "    file = open(savepath+filename.split('/')[-1].split('.')[0]+'.ann',mode='w')\n",
    "    input_text = file.write(result)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c61c2-7a06-478c-b111-367a770a7d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
